{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Welcome to Week 2!\n",
    "\n",
    "## Frontier Model APIs\n",
    "\n",
    "In Week 1, we used multiple Frontier LLMs through their Chat UI, and we connected with the OpenAI's API.\n",
    "\n",
    "Today we'll connect with the APIs for Anthropic and Google, as well as OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b268b6e-0ba4-461e-af86-74a41f4d681f",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Important Note - Please read me</h2>\n",
    "            <span style=\"color:#900;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in an Anaconda prompt (PC) or Terminal (Mac), run:<br/>\n",
    "            <code>conda env update --f environment.yml</code><br/>\n",
    "            Or if you used virtualenv rather than Anaconda, then run this from your activated environment in a Powershell (PC) or Terminal (Mac):<br/>\n",
    "            <code>pip install -r requirements.txt</code>\n",
    "            <br/>Then restart the kernel (Kernel menu >> Restart Kernel and Clear Outputs Of All Cells) to pick up the changes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder about the resources page</h2>\n",
    "            <span style=\"color:#f71;\">Here's a link to resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cfe275-4705-4d30-abea-643fbddf1db0",
   "metadata": {},
   "source": [
    "## Setting up your keys\n",
    "\n",
    "If you haven't done so already, you could now create API keys for Anthropic and Google in addition to OpenAI.\n",
    "\n",
    "**Please note:** if you'd prefer to avoid extra API costs, feel free to skip setting up Anthopic and Google! You can see me do it, and focus on OpenAI for the course. You could also substitute Anthropic and/or Google for Ollama, using the exercise you did in week 1.\n",
    "\n",
    "For OpenAI, visit https://openai.com/api/  \n",
    "For Anthropic, visit https://console.anthropic.com/  \n",
    "For Google, visit https://ai.google.dev/gemini-api  \n",
    "\n",
    "### Also - adding DeepSeek if you wish\n",
    "\n",
    "Optionally, if you'd like to also use DeepSeek, create an account [here](https://platform.deepseek.com/), create a key [here](https://platform.deepseek.com/api_keys) and top up with at least the minimum $2 [here](https://platform.deepseek.com/top_up).\n",
    "\n",
    "### Adding API keys to your .env file\n",
    "\n",
    "When you get your API keys, you need to set them as environment variables by adding them to your `.env` file.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxx\n",
    "ANTHROPIC_API_KEY=xxxx\n",
    "GOOGLE_API_KEY=xxxx\n",
    "DEEPSEEK_API_KEY=xxxx\n",
    "```\n",
    "\n",
    "Afterwards, you may need to restart the Jupyter Lab Kernel (the Python process that sits behind this notebook) via the Kernel menu, and then rerun the cells from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyAR\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425ed580-808d-429b-85b0-6cba50ca1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f77b59-2fb1-462a-b90d-78994e4cef33",
   "metadata": {},
   "source": [
    "## Asking LLMs to tell a joke\n",
    "\n",
    "It turns out that LLMs don't do a great job of telling jokes! Let's compare a few models.\n",
    "Later we will be putting LLMs to better use!\n",
    "\n",
    "### What information is included in the API\n",
    "\n",
    "Typically we'll pass to the API:\n",
    "- The name of the model that should be used\n",
    "- A system message that gives overall context for the role the LLM is playing\n",
    "- A user message that provides the actual prompt\n",
    "\n",
    "There are other parameters that can be used, including **temperature** which is typically between 0 and 1; higher for more random output; lower for more focused and deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3879b6-9a55-4fed-a18c-1ea2edfaf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-4o-mini', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2d6beb-1b81-466f-8ed1-40bf51e7adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the graph?\n",
      "\n",
      "Because it had too many *points* and wasn't very *linear*!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4.1-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d2a549-9d6e-4ea0-9c3e-b96a39e9959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist go to therapy?\n",
      "\n",
      "Because they had too many unresolved issues and couldn't find the missing values!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4.1-nano - extremely fast and cheap\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4.1-nano',\n",
    "    messages=prompts\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f54beb-823f-4301-98cb-8b9a49f4ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the spreadsheet?\n",
      "\n",
      "Because she thought she could find a better ‚Äúmodel‚Äù!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4.1\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96232ef4-dc9e-430b-a9df-f516685e7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work? \n",
      "\n",
      "Because she heard the features were high-dimensional and needed to scale them!\n"
     ]
    }
   ],
   "source": [
    "# If you have access to this, here is the reasoning model o3-mini\n",
    "# This is trained to think through its response before replying\n",
    "# So it will take longer but the answer should be more reasoned - not that this helps..\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='o3-mini',\n",
    "    messages=prompts\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ecdb506-9f7c-4539-abae-0e78d7f31b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to go to the beach?\n",
      "\n",
      "Because they're afraid of getting caught in an infinite loop of waves!\n",
      "\n",
      "*badum tss* ü•Å\n"
     ]
    }
   ],
   "source": [
    "# Claude 3.7 Sonnet\n",
    "# API needs system message provided separately from user prompt\n",
    "# Also adding max_tokens\n",
    "\n",
    "message = claude.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "769c4017-4b3b-4e64-8da7-ef4dcbe3fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a light-hearted joke for data scientists:\n",
      "\n",
      "Why did the data scientist get kicked out of the aquarium?\n",
      "\n",
      "They kept trying to \"scale\" the fish data!"
     ]
    }
   ],
   "source": [
    "# Claude 3.7 Sonnet again\n",
    "# Now let's add in streaming back results\n",
    "# If the streaming looks strange, then please see the note below this cell!\n",
    "\n",
    "result = claude.messages.stream(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e17bc-cd46-4c23-b639-0c7b748e6c5a",
   "metadata": {},
   "source": [
    "## A rare problem with Claude streaming on some Windows boxes\n",
    "\n",
    "2 students have noticed a strange thing happening with Claude's streaming into Jupyter Lab's output -- it sometimes seems to swallow up parts of the response.\n",
    "\n",
    "To fix this, replace the code:\n",
    "\n",
    "`print(text, end=\"\", flush=True)`\n",
    "\n",
    "with this:\n",
    "\n",
    "`clean_text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")`  \n",
    "`print(clean_text, end=\"\", flush=True)`\n",
    "\n",
    "And it should work fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df48ce5-70f8-4643-9a50-b0b5bfdb66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the Python data scientist always calm during a crisis?\n",
      "\n",
      "Because they knew how to `try`, `except`, and `finally` keep their cool! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The API for Gemini has a slightly different structure.\n",
    "# I've heard that on some PCs, this Gemini code causes the Kernel to crash.\n",
    "# If that happens to you, please skip this cell and use the next cell instead - an alternative approach.\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49009a30-037d-41c8-b874-127f61c4aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's one for you:\n",
      "\n",
      "Why did the data scientist break up with the training data?\n",
      "\n",
      "... Because it had too many missing values and couldn't commit!\n",
      "\n",
      "*(Or another option, playing on a different pain point):*\n",
      "\n",
      "Why was the machine learning model always so confident?\n",
      "\n",
      "... Because it had 100% accuracy... on the training data!\n"
     ]
    }
   ],
   "source": [
    "# As an alternative way to use Gemini that bypasses Google's python API library,\n",
    "# Google released endpoints that means you can use Gemini via the client libraries for OpenAI!\n",
    "# We're also trying Gemini's latest reasoning/thinking model\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = gemini_via_openai_client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    messages=prompts\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f70c88-7ca9-470b-ad55-d93a57dcc0ab",
   "metadata": {},
   "source": [
    "## (Optional) Trying out the DeepSeek model\n",
    "\n",
    "### Let's ask DeepSeek a really hard question - both the Chat and the Reasoner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d0019fb-f6a8-45cb-962b-ef8bf7070d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek API Key exists and begins sk-\n"
     ]
    }
   ],
   "source": [
    "# Optionally if you wish to try DeekSeek, you can also use the OpenAI client library\n",
    "\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c72c871e-68d6-4668-9c27-96d52b77b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a light-hearted joke for your data scientist audience:\n",
      "\n",
      "**Why did the data scientist bring a ladder to the bar?**\n",
      "\n",
      "*Because they heard the drinks were on the house... and they wanted to optimize their access to the top shelf!*  \n",
      "\n",
      "*(Bonus: \"Also, they wanted to minimize the KL-divergence between their current state and 'happy hour'.\")*  \n",
      "\n",
      "Hope that gets a chuckle! Let me know if you'd like a pun about overfitting next. üòÑ\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Chat\n",
    "\n",
    "deepseek_via_openai_client = OpenAI(\n",
    "    api_key=deepseek_api_key, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "response = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=prompts,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b6e70f-700a-46cf-942f-659101ffeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "             {\"role\": \"user\", \"content\": \"How many words are there in your answer to this prompt\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66d1151c-2015-4e37-80c8-16bc16367cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alright, let's tackle this problem step by step. The question is: \"How many words are there in your answer to this prompt.\" At first glance, it seems straightforward, but when I think about it more deeply, it appears to be a self-referential or recursive question. Here's how I'm going to approach it:\n",
       "\n",
       "### Understanding the Question\n",
       "\n",
       "The question is asking for the word count of the answer that is being generated in response to it. This creates a situation where the content of the answer determines its own length, which in turn affects the answer itself. It's a bit like a snake eating its own tail‚Äîa self-referential loop.\n",
       "\n",
       "### Breaking It Down\n",
       "\n",
       "1. **Initial Answer Attempt**: Suppose I start writing an answer like, \"This answer contains X words.\" But to determine X, I need to know how many words are in that sentence. \n",
       "\n",
       "   - \"This answer contains X words.\" has 5 words (assuming X is one word regardless of its value).\n",
       "   - So, X should be 5. But then the sentence is \"This answer contains 5 words,\" which still has 5 words. This seems correct.\n",
       "\n",
       "   However, this is a very simplistic answer. The user might expect a more detailed explanation, not just a one-sentence response.\n",
       "\n",
       "2. **More Detailed Answer**: If I provide a more elaborate explanation, like what I'm doing now, the word count increases. But then the word count depends on the entire answer, which includes the word count itself.\n",
       "\n",
       "   - This creates a paradox because to state the word count, the word count must already be known, but it's being determined by the statement that includes it.\n",
       "\n",
       "### Potential Approaches\n",
       "\n",
       "a. **Fixed-Length Answer**: Provide a answer where the word count is fixed regardless of the explanation. For example, \"The word count is five.\" This has 5 words, and it's consistent.\n",
       "\n",
       "   - But this seems too minimal and doesn't address the recursive nature properly.\n",
       "\n",
       "b. **Self-Referential Calculation**: Calculate the word count as I write, adjusting until the number matches the actual count.\n",
       "\n",
       "   - For instance, if I say, \"This answer contains 10 words,\" but upon counting, it's actually 5, I adjust. But this could go on indefinitely unless the number stabilizes.\n",
       "\n",
       "c. **Meta-Response**: Acknowledge the recursion and explain why it's tricky without providing a fixed number.\n",
       "\n",
       "   - This seems like a cop-out and doesn't directly answer the question.\n",
       "\n",
       "### Testing the Fixed-Length Approach\n",
       "\n",
       "Let's try the fixed-length approach with a slightly more detailed answer:\n",
       "\n",
       "\"Your answer contains exactly seven words here.\"\n",
       "\n",
       "Counting the words:\n",
       "1. Your\n",
       "2. answer\n",
       "3. contains\n",
       "4. exactly\n",
       "5. seven\n",
       "6. words\n",
       "7. here.\n",
       "\n",
       "That's 7 words. It matches. So, this seems to work.\n",
       "\n",
       "But is this the only possible correct answer? Let's try another:\n",
       "\n",
       "\"The number of words in this response is ten.\"\n",
       "\n",
       "Counting:\n",
       "1. The\n",
       "2. number\n",
       "3. of\n",
       "4. words\n",
       "5. in\n",
       "6. this\n",
       "7. response\n",
       "8. is\n",
       "9. ten\n",
       "10. .\n",
       "\n",
       "That's 10 words if we count the period as a word (which we typically don't). Without the period, it's 9 words, so it doesn't match. So, \"ten\" is incorrect; it should be \"nine.\" Then:\n",
       "\n",
       "\"The number of words in this response is nine.\"\n",
       "\n",
       "Counting:\n",
       "1. The\n",
       "2. number\n",
       "3. of\n",
       "4. words\n",
       "5. in\n",
       "6. this\n",
       "7. response\n",
       "8. is\n",
       "9. nine\n",
       "10. .\n",
       "\n",
       "Still 9 words (excluding the period). So this also works.\n",
       "\n",
       "Hmm, so there are multiple possible correct answers where the stated number matches the actual word count.\n",
       "\n",
       "### Generalizing the Solution\n",
       "\n",
       "Any sentence of the form \"[Sentence] X [words-related phrase].\" where the number of words in the entire sentence is X, is a correct answer.\n",
       "\n",
       "Examples:\n",
       "- \"This answer has five words.\" (5 words)\n",
       "- \"The word count of this reply is seven.\" (7 words)\n",
       "- \"There are eight words in this answer I'm giving.\" (8 words)\n",
       "\n",
       "Each of these is correct because the stated number matches the actual word count.\n",
       "\n",
       "### Choosing the Optimal Answer\n",
       "\n",
       "Given that there are infinitely many correct answers (for different X where the sentence structure allows), the simplest is probably the shortest one that still makes sense. \n",
       "\n",
       "\"The word count is five.\" (5 words) is correct but very minimal.\n",
       "\n",
       "A slightly more informative one could be: \"This answer contains seven words in total.\" Let's count:\n",
       "\n",
       "1. This\n",
       "2. answer\n",
       "3. contains\n",
       "4. seven\n",
       "5. words\n",
       "6. in\n",
       "7. total.\n",
       "\n",
       "Yes, 7 words. This seems better.\n",
       "\n",
       "### Verifying\n",
       "\n",
       "Let me write that answer and count:\n",
       "\n",
       "\"This answer contains seven words in total.\"\n",
       "\n",
       "Counting:\n",
       "1. This\n",
       "2. answer\n",
       "3. contains\n",
       "4. seven\n",
       "5. words\n",
       "6. in\n",
       "7. total.\n",
       "\n",
       "Yes, it's indeed 7 words. \n",
       "\n",
       "### Conclusion\n",
       "\n",
       "After exploring different approaches, the most straightforward and correct way to answer is to provide a sentence where the declared word count matches the actual number of words in that sentence. Here's one such answer:\n",
       "\n",
       "\"This answer contains seven words in total.\"\n",
       "\n",
       "### Final Answer\n",
       "\n",
       "This answer contains seven words in total."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 747\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Chat with a harder question! And streaming results\n",
    "\n",
    "stream = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=challenge,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a93f7d-9300-48cc-8c1a-ee67380db495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user is asking how many words are in my answer to this prompt. Let me start by understanding the question properly. They want to know the word count of the response I'm generating right now. \n",
      "\n",
      "First, I need to make sure I follow the instructions. The user mentioned that I should start with \"Alright, so...\" and then think through the problem step by step. Then, after that thinking process, I should provide the final answer in the specified format.\n",
      "\n",
      "So, my response will have two parts: the thinking process and the final answer. The user wants the word count of the entire answer, which includes both parts. Wait, but the initial instruction says \"your answer to this prompt\"‚Äîdoes that mean just the final answer, or the entire response including the thinking part?\n",
      "\n",
      "Looking back at the example given, the assistant's response includes both the thinking and the final answer. In the example, the user asked a similar question, and the assistant provided a thought process followed by the answer. The word count included both parts. So, following that pattern, I should count all the words in both sections.\n",
      "\n",
      "Let me start drafting the thinking process. I need to explain how I arrived at the word count. I'll mention that I need to consider both the thinking part and the final answer. Then, I'll write out the thinking process, making sure to use the required phrases like \"step by step\" and \"make sure to adhere to the instructions.\"\n",
      "\n",
      "Wait, but in the user's message, they included an example where the assistant's response had a thinking section and then the answer. The example's final answer was just a number in a box. So perhaps the user wants the word count of the entire response, including both the thinking and the final answer. But in the example, the assistant's final answer was only the number, but the user's question was about the answer to the prompt, which might refer to the entire response.\n",
      "\n",
      "Alternatively, maybe the user is asking for the word count of the assistant's answer to the current prompt, which is the answer they're about to receive. So, in this case, after I write out my thinking process and the final answer, I need to count all the words in both parts combined.\n",
      "\n",
      "But how do I calculate that before writing it? I need to generate the thinking process, then the answer, and then count the words. But since I can't know the exact word count until I write it, perhaps I should write the thinking process first, then count the words in it and the final answer. However, since this is a single response, I need to generate the entire response, including the thinking and the answer, then count the words in that entire response.\n",
      "\n",
      "Wait, but that creates a paradox because the response includes the word count of itself. How can I include the word count before I finish writing it? This is a common issue when dealing with self-referential questions. The way to handle this is to write the entire response, then count the words, but since the response must include the count, I have to estimate it first, write the response, then adjust the count if necessary.\n",
      "\n",
      "Alternatively, perhaps the user is aware of this and expects the assistant to approximate the word count. But in the example provided earlier, the assistant's answer was straightforward, counting the words in their response. Let me check that example again. In the example, the user asked how many words are in the assistant's response, and the assistant provided a thought process and then the answer in a box. The final count was 45, which included both the thinking and the answer. So following that example, I need to do the same here.\n",
      "\n",
      "Therefore, my approach should be:\n",
      "\n",
      "1. Write the thinking process, which is the current text I'm generating.\n",
      "2. Write the final answer, which is the word count of the entire response, including both the thinking and the answer.\n",
      "3. However, since the final answer is part of the response, the word count must include the final answer's text as well.\n",
      "\n",
      "But how can I accurately count the words before the response is complete? I need to draft the entire response first, then count the words, then adjust the final answer accordingly. However, in practice, the assistant generates the response step by step. So perhaps the correct method is to:\n",
      "\n",
      "- Write the thinking process, then the final answer.\n",
      "- Then, count all the words in both sections.\n",
      "- Insert that count into the final answer.\n",
      "\n",
      "But since the assistant's response is generated in one go, I need to simulate that process here. Let's proceed step by step.\n",
      "\n",
      "First, draft the thinking process. Then, write the final answer. Then, count the words in both parts. Let's do that.\n",
      "\n",
      "Thinking process:\n",
      "\n",
      "Alright, so the user is asking for the number of words in my response to their prompt. I need to make sure I count all the words in both my thinking process and the final answer. Let me break it down. First, I'll write out my thought process, explaining how I arrived at the answer. Then, I'll provide the final answer in the specified format. Each part contributes to the total word count. I'll need to be careful to include every word, including contractions and hyphenated words as single words. Once I've written both sections, I'll count each word individually to get the accurate total.\n",
      "\n",
      "Final answer:\n",
      "\n",
      "The total number of words in my response is determined by counting each word in both the thinking process and this final answer. After writing out the entire response, I tally all the words to ensure accuracy.\n",
      "\n",
      "Wait, but this is the actual content I need to generate. Let me adjust. The actual thinking process would be as above, and then the final answer is a box with the number. But to get the number, I need to count the words in the thinking process and the final answer.\n",
      "\n",
      "But since the final answer is just a number in a box, like \\boxed{45}, then perhaps the word count includes the entire response up to that point. Let's try to simulate this.\n",
      "\n",
      "First, I write the thinking process:\n",
      "\n",
      "Alright, so the user wants to know the number of words in my response to this prompt. I need to consider both the thought process explanation and the final answer. Let me start by outlining my approach. I'll first explain how I plan to count the words, then proceed to write the final answer. Each word in these sentences contributes to the total count. I should avoid missing any words, including small ones like \"a\" or \"is\". Once I finish writing this thinking section, I'll move on to the final answer, which will be a boxed number. The key is to ensure that the count includes every single word in the entire response, from start to finish.\n",
      "\n",
      "Now, the final answer is just \\boxed{X}, where X is the number. But how many words are in the thinking process above? Let's count:\n",
      "\n",
      "\"Alright, so the user wants to know the number of words in my response to this prompt. I need to consider both the thought process explanation and the final answer. Let me start by outlining my approach. I'll first explain how I plan to count the words, then proceed to write the final answer. Each word in these sentences contributes to the total count. I should avoid missing any words, including small ones like \"a\" or \"is\". Once I finish writing this thinking section, I'll move on to the final answer, which will be a boxed number. The key is to ensure that the count includes every single word in the entire response, from start to finish.\"\n",
      "\n",
      "Let's break this into words:\n",
      "\n",
      "1. Alright\n",
      "2. so\n",
      "3. the\n",
      "4. user\n",
      "5. wants\n",
      "6. to\n",
      "7. know\n",
      "8. the\n",
      "9. number\n",
      "10. of\n",
      "11. words\n",
      "12. in\n",
      "13. my\n",
      "14. response\n",
      "15. to\n",
      "16. this\n",
      "17. prompt.\n",
      "18. I\n",
      "19. need\n",
      "20. to\n",
      "21. consider\n",
      "22. both\n",
      "23. the\n",
      "24. thought\n",
      "25. process\n",
      "26. explanation\n",
      "27. and\n",
      "28. the\n",
      "29. final\n",
      "30. answer.\n",
      "31. Let\n",
      "32. me\n",
      "33. start\n",
      "34. by\n",
      "35. outlining\n",
      "36. my\n",
      "37. approach.\n",
      "38. I'll\n",
      "39. first\n",
      "40. explain\n",
      "41. how\n",
      "42. I\n",
      "43. plan\n",
      "44. to\n",
      "45. count\n",
      "46. the\n",
      "47. words,\n",
      "48. then\n",
      "49. proceed\n",
      "50. to\n",
      "51. write\n",
      "52. the\n",
      "53. final\n",
      "54. answer.\n",
      "55. Each\n",
      "56. word\n",
      "57. in\n",
      "58. these\n",
      "59. sentences\n",
      "60. contributes\n",
      "61. to\n",
      "62. the\n",
      "63. total\n",
      "64. count.\n",
      "65. I\n",
      "66. should\n",
      "67. avoid\n",
      "68. missing\n",
      "69. any\n",
      "70. words,\n",
      "71. including\n",
      "72. small\n",
      "73. ones\n",
      "74. like\n",
      "75. \"a\"\n",
      "76. or\n",
      "77. \"is\".\n",
      "78. Once\n",
      "79. I\n",
      "80. finish\n",
      "81. writing\n",
      "82. this\n",
      "83. thinking\n",
      "84. section,\n",
      "85. I'll\n",
      "86. move\n",
      "87. on\n",
      "88. to\n",
      "89. the\n",
      "90. final\n",
      "91. answer,\n",
      "92. which\n",
      "93. will\n",
      "94. be\n",
      "95. a\n",
      "96. boxed\n",
      "97. number.\n",
      "98. The\n",
      "99. key\n",
      "100. is\n",
      "101. to\n",
      "102. ensure\n",
      "103. that\n",
      "104. the\n",
      "105. count\n",
      "106. includes\n",
      "107. every\n",
      "108. single\n",
      "109. word\n",
      "110. in\n",
      "111. the\n",
      "112. entire\n",
      "113. response,\n",
      "114. from\n",
      "115. start\n",
      "116. to\n",
      "117. finish.\n",
      "\n",
      "That's 117 words in the thinking process. Then the final answer is \"\\boxed{117}\". But wait, the final answer is just the boxed number, which is one \"word\" if we consider it as a single token, but in terms of actual words, \"\\boxed{117}\" is not a word‚Äîit's LaTeX syntax. However, the user is asking for the number of words in the answer. So, does the LaTeX code count as words? For example, \"boxed\" and \"117\" would be separate words? Let me clarify.\n",
      "\n",
      "If we consider the final answer as written in the response, which is \"\\boxed{117}\", then breaking it down:\n",
      "\n",
      "- \\boxed{ is a LaTeX command. The backslash and \"boxed\" would be considered as one part.\n",
      "- 117 is the number inside the box.\n",
      "- The closing } is another part.\n",
      "\n",
      "But in terms of plain text words, the entire \"\\boxed{117}\" is not composed of standard words. However, if the assistant's response is in plain text, then \"\\boxed{117}\" is a sequence of characters, not actual words. Therefore, the final answer, as presented, does not contain any words‚Äîit's a LaTeX-formatted box. However, in the example provided by the user earlier, the assistant's final answer was \"\\boxed{45}\" and that counted as part of the word count. Wait, no‚Äîin the example, the user asked how many words were in the assistant's answer, and the assistant's answer was 45 words, which included both the thinking process and the final answer. The final answer itself, being just the boxed number, was not counted as words but the rest of the text was.\n",
      "\n",
      "Wait, no. In the example, the assistant's response was:\n",
      "\n",
      "\"Alright, let's figure this out. The user is asking for the number of words in my response. I need to count all the words in both my thinking process and the final answer. Let me start by writing out this thought process, which will contribute to the total word count. Once I finish explaining my steps, I'll provide the final count in a box. Each word here adds to the total, so I need to be careful. Alright, I think that's enough for the thinking part. Now, onto the final answer. The total number of words is...\"\n",
      "\n",
      "Then the final answer was \\boxed{45}. So in that case, the word count included all the words in the thinking process and the final answer's explanation. But the boxed number itself was part of the final answer, but in that example, the assistant's response was the entire text, including the thinking and the final answer. The user's question was about the entire answer, so the 45 words included both the thinking and the final answer text, but the boxed number was just the representation of the count, not part of the word count.\n",
      "\n",
      "Wait, this is confusing. Let me think again. If the assistant writes a response that includes both the thinking process and the final answer (the boxed number), the word count is the total number of words in the entire response, excluding the boxed number if it's just a LaTeX command. But in reality, the boxed number is part of the text. For example, if the assistant writes:\n",
      "\n",
      "\"Thinking process... Final answer: \\boxed{45}.\"\n",
      "\n",
      "In plain text, \"\\boxed{45}\" is 1 \"word\" if we consider it a single token, but technically, it's multiple characters. However, standard word counts treat each sequence of characters separated by spaces as a word. So if the final answer is written as \"\\boxed{45}\", that would be counted as one word. But in the example, the assistant's response had 45 words, which included all the text before the boxed number. Therefore, the boxed number itself wasn't counted as a word because it's part of the final answer's formatting, not actual words.\n",
      "\n",
      "Wait, no. In the example, the assistant's answer was the entire text, including the thinking process and the final answer. The user's question was about the word count of the entire answer. So the assistant's response had 45 words in total, which included all the words in the thinking process and the final answer's text, but the boxed number was just the representation of the count, not part of the word count. Wait, that doesn't make sense. It's a bit of a paradox because the boxed number is part of the answer, but the answer's word count includes it. However, since the boxed number is a LaTeX command, it's not a word. But in plain text, if you write \"\\boxed{45}\", that's one word if you consider it as a single token. But standard word counts may not count LaTeX commands as words. This is getting too complicated.\n",
      "\n",
      "Alternatively, perhaps the user expects the assistant to follow the example where the assistant's response, including the thinking process and the final answer (the boxed number), has a total word count that is stated in the boxed number. In the example, the assistant's response was 45 words, which included the entire text up to the boxed number, and the boxed number was just the answer. So the boxed number is not included in the word count. Therefore, in this case, the assistant should count all the words in the thinking process and the final answer's text (excluding the boxed number itself) and put that number in the box.\n",
      "\n",
      "But how does that work? Let's look at the example again. The user's prompt was: \"How many words are there in your answer to this prompt\". The assistant's response was a thinking process followed by \\boxed{45}. The actual word count of the entire response (the thinking process and the final answer's text) was 45 words. Therefore, the boxed number is the result of that count, not part of the count itself.\n",
      "\n",
      "Therefore, in this current case, the assistant needs to generate the thinking process, then state the final answer as \\boxed{X}, where X is the number of words in the entire response (thinking + final answer text). But wait, the final answer text is just the boxed number. So the total words would be the words in the thinking process plus the words in the final answer. However, the final answer is just \"\\boxed{X}\", which, as plain text, could be considered as one word (if we count \"\\boxed{X}\" as a single word) or multiple parts. But in standard word counting, LaTeX commands might not be split into words. For example, in the example, the assistant's response had 45 words, which included the entire thinking process and the final answer's text (which was the sentence leading up to the boxed number). Wait, no‚Äîthe example's final answer was just the boxed number, but the thinking process was several sentences. Let me check the example again.\n",
      "\n",
      "The example given by the user in their initial message was:\n",
      "\n",
      "User: How many words are there in your answer to this prompt\n",
      "\n",
      "Assistant: Alright, let's figure this out. The user is asking for the number of words in my response. I need to count all the words in both my thinking process and the final answer. Let me start by writing out this thought process, which will contribute to the total word count. Once I finish explaining my steps, I'll provide the final count in a box. Each word here adds to the total, so I need to be careful. Alright, I think that's enough for the thinking part. Now, onto the final answer. The total number of words is... \\boxed{45}\n",
      "\n",
      "In this case, the assistant's response includes the thinking process and the final answer text (\"The total number of words is...\") followed by the boxed number. The word count of 45 includes all the words in the thinking process and the final answer text up to the boxed number. The boxed number itself is not counted because it's a LaTeX command and not part of the actual text words. So in this example, the final answer text is \"The total number of words is...\", which contributes to the word count, and the boxed number is just the answer. Therefore, the assistant's entire response (the thinking process plus the final answer text) totals 45 words.\n",
      "\n",
      "Therefore, in the current scenario, the assistant's response should include a thinking process and a final answer text (like \"The total number of words is...\") followed by the boxed number. The word count includes all the words in the thinking process and the final answer text, but not the boxed number itself.\n",
      "\n",
      "Wait, but in the example, the final answer text is \"The total number of words is...\", which is part of the response and thus included in the word count. The boxed number is just the numerical answer, not part of the word count. Therefore, when the user asks for the number of words in the assistant's answer, they are referring to the entire textual response, excluding the boxed number, which is a formatting element.\n",
      "\n",
      "But this is inconsistent because the boxed number is part of the assistant's answer. However, in the example, the word count was 45, which included all the text up to the boxed number. Therefore, the correct approach is to count all the words in the thinking process and any explanatory text leading up to the boxed number, but the boxed number itself is not counted as a word.\n",
      "\n",
      "Therefore, in the current case, the assistant should write out the thinking process and any explanatory text, count all those words, and then present the count in a box. The boxed number is not included in the word count.\n",
      "\n",
      "Applying that to the current problem:\n",
      "\n",
      "1. Write the thinking process (this text).\n",
      "2. Write the final answer text (e.g., \"The total number of words in my response is\").\n",
      "3. Count the words in steps 1 and 2.\n",
      "4. Present the count in a box.\n",
      "\n",
      "But in the example, the assistant's final answer text was included in the word count. For instance, in the example, \"The total number of words is...\" was part of the word count. Therefore, in our case, the final answer text is part of the response and must be included in the word count.\n",
      "\n",
      "Therefore, the steps are:\n",
      "\n",
      "- Generate the thinking process text.\n",
      "- Generate the final answer text (including any words leading up to the boxed number).\n",
      "- Count all the words in both sections.\n",
      "- Place the count in a box.\n",
      "\n",
      "So, for the current response, the assistant needs to:\n",
      "\n",
      "1. Write the thinking process.\n",
      "2. Write something like \"The total number of words in my answer is \\boxed{X}.\"\n",
      "3. Count all the words in the thinking process plus the final answer sentence (excluding the boxed number itself).\n",
      "\n",
      "Wait, but if the final answer is \"The total number of words in my answer is \\boxed{X}.\", then the words in that sentence are included in the count. The boxed number is just a representation of X, not part of the word count.\n",
      "\n",
      "Therefore, to calculate X, the assistant must count all words in the thinking process and the final answer sentence (excluding the boxed number).\n",
      "\n",
      "This seems complicated, but let's proceed.\n",
      "\n",
      "First, draft the thinking process:\n",
      "\n",
      "Alright, so the user is asking how many words are in my response to this prompt. I need to ensure I count every word in both my thinking process and the final answer. Let me start by outlining my approach. First, I'll explain my thought process step by step, making sure to include all relevant details. Then, I'll provide the final answer, which includes the total word count. Each word here contributes to the total, so I need to be precise. Once I finish this explanation, I'll tally up all the words to get the accurate number. It's important to count contractions and hyphenated words as single words. After careful consideration, I'll present the final count in a box.\n",
      "\n",
      "Next, draft the final answer sentence:\n",
      "\n",
      "The total number of words in my answer is \\boxed{X}.\n",
      "\n",
      "Now, count the words in the thinking process:\n",
      "\n",
      "\"Alright, so the user is asking how many words are in my response to this prompt. I need to ensure I count every word in both my thinking process and the final answer. Let me start by outlining my approach. First, I'll explain my thought process step by step, making sure to include all relevant details. Then, I'll provide the final answer, which includes the total word count. Each word here contributes to the total, so I need to be precise. Once I finish this explanation, I'll tally up all the words to get the accurate number. It's important to count contractions and hyphenated words as single words. After careful consideration, I'll present the final count in a box.\"\n",
      "\n",
      "Breaking this into words:\n",
      "\n",
      "1. Alright\n",
      "2. so\n",
      "3. the\n",
      "4. user\n",
      "5. is\n",
      "6. asking\n",
      "7. how\n",
      "8. many\n",
      "9. words\n",
      "10. are\n",
      "11. in\n",
      "12. my\n",
      "13. response\n",
      "14. to\n",
      "15. this\n",
      "16. prompt.\n",
      "17. I\n",
      "18. need\n",
      "19. to\n",
      "20. ensure\n",
      "21. I\n",
      "22. count\n",
      "23. every\n",
      "24. word\n",
      "25. in\n",
      "26. both\n",
      "27. my\n",
      "28. thinking\n",
      "29. process\n",
      "30. and\n",
      "31. the\n",
      "32. final\n",
      "33. answer.\n",
      "34. Let\n",
      "35. me\n",
      "36. start\n",
      "37. by\n",
      "38. outlining\n",
      "39. my\n",
      "40. approach.\n",
      "41. First,\n",
      "42. I'll\n",
      "43. explain\n",
      "44. my\n",
      "45. thought\n",
      "46. process\n",
      "47. step\n",
      "48. by\n",
      "49. step,\n",
      "50. making\n",
      "51. sure\n",
      "52. to\n",
      "53. include\n",
      "54. all\n",
      "55. relevant\n",
      "56. details.\n",
      "57. Then,\n",
      "58. I'll\n",
      "59. provide\n",
      "60. the\n",
      "61. final\n",
      "62. answer,\n",
      "63. which\n",
      "64. includes\n",
      "65. the\n",
      "66. total\n",
      "67. word\n",
      "68. count.\n",
      "69. Each\n",
      "70. word\n",
      "71. here\n",
      "72. contributes\n",
      "73. to\n",
      "74. the\n",
      "75. total,\n",
      "76. so\n",
      "77. I\n",
      "78. need\n",
      "79. to\n",
      "80. be\n",
      "81. precise.\n",
      "82. Once\n",
      "83. I\n",
      "84. finish\n",
      "85. this\n",
      "86. explanation,\n",
      "87. I'll\n",
      "88. tally\n",
      "89. up\n",
      "90. all\n",
      "91. the\n",
      "92. words\n",
      "93. to\n",
      "94. get\n",
      "95. the\n",
      "96. accurate\n",
      "97. number.\n",
      "98. It's\n",
      "99. important\n",
      "100. to\n",
      "101. count\n",
      "102. contractions\n",
      "103. and\n",
      "104. hyphenated\n",
      "105. words\n",
      "106. as\n",
      "107. single\n",
      "108. words.\n",
      "109. After\n",
      "110. careful\n",
      "111. consideration,\n",
      "112. I'll\n",
      "113. present\n",
      "114. the\n",
      "115. final\n",
      "116. count\n",
      "117. in\n",
      "118. a\n",
      "119. box.\n",
      "\n",
      "That's 119 words in the thinking process.\n",
      "\n",
      "Now, the final answer sentence: \"The total number of words in my answer is \\boxed{X}.\"\n",
      "\n",
      "Breaking into words:\n",
      "\n",
      "1. The\n",
      "2. total\n",
      "3. number\n",
      "4. of\n",
      "5. words\n",
      "6. in\n",
      "7. my\n",
      "8. answer\n",
      "9. is\n",
      "\n",
      "That's 9 words.\n",
      "\n",
      "Total words in the response: 119 (thinking) + 9 (final answer text) = 128 words.\n",
      "\n",
      "Therefore, the final answer would be \\boxed{128}.\n",
      "\n",
      "But wait, this is the count for this specific example. However, in reality, when the assistant generates the response, the actual word count might differ based on the exact wording. For instance, the thinking process I just wrote is longer than the example, so the count here would be different.\n",
      "\n",
      "But in reality, the assistant would generate the thinking process and then the final answer, and then count the words. However, since I'm simulating this process, I need to ensure that the count is accurate.\n",
      "\n",
      "Wait, let's recount the thinking process to be precise. The thinking process I drafted earlier has 119 words. Let me verify:\n",
      "\n",
      "\"Alright, so the user is asking how many words are in my response to this prompt. I need to ensure I count every word in both my thinking process and the final answer. Let me start by outlining my approach. First, I'll explain my thought process step by step, making sure to include all relevant details. Then, I'll provide the final answer, which includes the total word count. Each word here contributes to the total, so I need to be precise. Once I finish this explanation, I'll tally up all the words to get the accurate number. It's important to count contractions and hyphenated words as single words. After careful consideration, I'll present the final count in a box.\"\n",
      "\n",
      "Let me count this again manually:\n",
      "\n",
      "1. Alright\n",
      "2. so\n",
      "3. the\n",
      "4. user\n",
      "5. is\n",
      "6. asking\n",
      "7. how\n",
      "8. many\n",
      "9. words\n",
      "10. are\n",
      "11. in\n",
      "12. my\n",
      "13. response\n",
      "14. to\n",
      "15. this\n",
      "16. prompt.\n",
      "17. I\n",
      "18. need\n",
      "19. to\n",
      "20. ensure\n",
      "21. I\n",
      "22. count\n",
      "23. every\n",
      "24. word\n",
      "25. in\n",
      "26. both\n",
      "27. my\n",
      "28. thinking\n",
      "29. process\n",
      "30. and\n",
      "31. the\n",
      "32. final\n",
      "33. answer.\n",
      "34. Let\n",
      "35. me\n",
      "36. start\n",
      "37. by\n",
      "38. outlining\n",
      "39. my\n",
      "40. approach.\n",
      "41. First,\n",
      "42. I'll\n",
      "43. explain\n",
      "44. my\n",
      "45. thought\n",
      "46. process\n",
      "47. step\n",
      "48. by\n",
      "49. step,\n",
      "50. making\n",
      "51. sure\n",
      "52. to\n",
      "53. include\n",
      "54. all\n",
      "55. relevant\n",
      "56. details.\n",
      "57. Then,\n",
      "58. I'll\n",
      "59. provide\n",
      "60. the\n",
      "61. final\n",
      "62. answer,\n",
      "63. which\n",
      "64. includes\n",
      "65. the\n",
      "66. total\n",
      "67. word\n",
      "68. count.\n",
      "69. Each\n",
      "70. word\n",
      "71. here\n",
      "72. contributes\n",
      "73. to\n",
      "74. the\n",
      "75. total,\n",
      "76. so\n",
      "77. I\n",
      "78. need\n",
      "79. to\n",
      "80. be\n",
      "81. precise.\n",
      "82. Once\n",
      "83. I\n",
      "84. finish\n",
      "85. this\n",
      "86. explanation,\n",
      "87. I'll\n",
      "88. tally\n",
      "89. up\n",
      "90. all\n",
      "91. the\n",
      "92. words\n",
      "93. to\n",
      "94. get\n",
      "95. the\n",
      "96. accurate\n",
      "97. number.\n",
      "98. It's\n",
      "99. important\n",
      "100. to\n",
      "101. count\n",
      "102. contractions\n",
      "103. and\n",
      "104. hyphenated\n",
      "105. words\n",
      "106. as\n",
      "107. single\n",
      "108. words.\n",
      "109. After\n",
      "110. careful\n",
      "111. consideration,\n",
      "112. I'll\n",
      "113. present\n",
      "114. the\n",
      "115. final\n",
      "116. count\n",
      "117. in\n",
      "118. a\n",
      "119. box.\n",
      "\n",
      "Yes, 119 words. Then the final answer text \"The total number of words in my answer is \\boxed{X}.\" is 9 words. So total is 128 words.\n",
      "\n",
      "However, in this case, the assistant's response would be:\n",
      "\n",
      "[Thinking process as above]\n",
      "\n",
      "The total number of words in my answer is \\boxed{128}.\n",
      "\n",
      "But this is a simulation. However, the actual response the assistant is generating now needs to have the correct word count. But since the assistant can't know the count before writing, this is a bit of a challenge. Therefore, the correct approach is to write the thinking process and the final answer text, count the words, and then put the number in the box. However, in practice, the assistant would need to generate the response with the correct count in real-time.\n",
      "\n",
      "In the example provided by the user, the assistant's response had 45 words. That's a manageable number. So perhaps the assistant's response here will have around 100 words, depending on the verbosity.\n",
      "\n",
      "Alternatively, perhaps the assistant can provide a general method for counting the words, and then state the final count. However, the user is asking for the specific number.\n",
      "\n",
      "Given the complexity, the assistant should generate a thinking process and then the final answer with the correct word count, ensuring that the count includes all words in the response.\n",
      "Alright, so the user is asking how many words are in my response to this prompt. To determine this, I need to count every word in both the thinking process and the final answer. Let me start by outlining my approach. I'll explain my thought process step by step, then provide the final count. Each word here contributes to the total, so I'll ensure accuracy by counting each one carefully. Once I finish this explanation, I'll tally all the words and present the result in a box. Contractions and hyphenated words count as single words. After careful consideration, the total word count is calculated and ready to be shared.  \n",
      "\n",
      "The total number of words in my answer is \\boxed{126}.\n",
      "Number of words: 120\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Reasoner - this may hit an error if DeepSeek is busy\n",
    "# It's over-subscribed (as of 28-Jan-2025) but should come back online soon!\n",
    "# If this fails, come back to this in a few days..\n",
    "\n",
    "response = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    messages=challenge\n",
    ")\n",
    "\n",
    "reasoning_content = response.choices[0].message.reasoning_content\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print(reasoning_content)\n",
    "print(content)\n",
    "print(\"Number of words:\", len(content.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0d5dd-7f20-4090-a46d-da56ceec218f",
   "metadata": {},
   "source": [
    "## Additional exercise to build your experience with the models\n",
    "\n",
    "This is optional, but if you have time, it's so great to get first hand experience with the capabilities of these different models.\n",
    "\n",
    "You could go back and ask the same question via the APIs above to get your own personal experience with the pros & cons of the models.\n",
    "\n",
    "Later in the course we'll look at benchmarks and compare LLMs on many dimensions. But nothing beats personal experience!\n",
    "\n",
    "Here are some questions to try:\n",
    "1. The question above: \"How many words are there in your answer to this prompt\"\n",
    "2. A creative question: \"In 3 sentences, describe the color Blue to someone who's never been able to see\"\n",
    "3. A student (thank you Roman) sent me this wonderful riddle, that apparently children can usually answer, but adults struggle with: \"On a bookshelf, two volumes of Pushkin stand side by side: the first and the second. The pages of each volume together have a thickness of 2 cm, and each cover is 2 mm thick. A worm gnawed (perpendicular to the pages) from the first page of the first volume to the last page of the second volume. What distance did it gnaw through?\".\n",
    "\n",
    "The answer may not be what you expect, and even though I'm quite good at puzzles, I'm embarrassed to admit that I got this one wrong.\n",
    "\n",
    "### What to look out for as you experiment with models\n",
    "\n",
    "1. How the Chat models differ from the Reasoning models (also known as Thinking models)\n",
    "2. The ability to solve problems and the ability to be creative\n",
    "3. Speed of generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e6b5c-6816-4cd3-a5cd-a20e4171b1a0",
   "metadata": {},
   "source": [
    "## Back to OpenAI with a serious question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ddb483-4f57-4668-aeea-2aade3a9e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "749f50ab-8ccd-4502-a521-895c3f0808a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Deciding if a Business Problem is Suitable for an LLM Solution\n",
       "\n",
       "When considering whether to apply a Large Language Model (LLM) to a business problem, you should evaluate several key factors. Here‚Äôs a structured approach to help you make that decision:\n",
       "\n",
       "## 1. Nature of the Problem\n",
       "- **Text-Based Data**: Is the problem primarily related to text, such as customer inquiries, documents, or reports?\n",
       "- **Language Understanding**: Does the problem require understanding or generating human language?\n",
       "\n",
       "## 2. Use Case Suitability\n",
       "- **Automation Potential**: Can the problem be automated? Examples include chatbots, content generation, or data extraction.\n",
       "- **Complexity**: Is the problem complex enough that traditional rule-based systems would be inefficient or ineffective?\n",
       "\n",
       "## 3. Data Availability\n",
       "- **Quality of Data**: Do you have high-quality, relevant text data to train or fine-tune the LLM?\n",
       "- **Volume of Data**: Is there a sufficient amount of data to ensure the model learns effectively?\n",
       "\n",
       "## 4. Business Impact\n",
       "- **Value Addition**: Will solving the problem with an LLM provide significant value or efficiency gains?\n",
       "- **Cost-Benefit Analysis**: Are the potential benefits worth the investment in LLM technology and infrastructure?\n",
       "\n",
       "## 5. Technical Feasibility\n",
       "- **Integration**: Can the LLM be integrated into existing systems and workflows?\n",
       "- **Expertise**: Does your team have the necessary skills to implement and maintain LLM solutions?\n",
       "\n",
       "## 6. Ethical Considerations\n",
       "- **Bias and Fairness**: Are there concerns about bias in the model that could affect outcomes?\n",
       "- **Compliance**: Does the problem involve sensitive data that may raise privacy or regulatory issues?\n",
       "\n",
       "## 7. Alternatives\n",
       "- **Existing Solutions**: Are there already effective solutions available for the problem that do not require LLMs?\n",
       "- **Comparative Analysis**: Would simpler models or approaches be more efficient or cost-effective?\n",
       "\n",
       "## Conclusion\n",
       "If your business problem aligns well with the factors outlined above, it may be suitable for an LLM solution. Conducting a thorough analysis will help ensure that you make an informed decision that aligns with your business goals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09351-1fbe-422f-8b25-f50826ab4c5f",
   "metadata": {},
   "source": [
    "## And now for some fun - an adversarial conversation between Chatbots..\n",
    "\n",
    "You're already familar with prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb54183-45d3-4d08-b5b6-55e380dfdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "claude_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1df47dc7-b445-4852-b21b-59f0e6c2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, claude in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dc6e913-02be-4eb6-9581-ad4b2cffa606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, wow, what a groundbreaking greeting. Have you considered using something more original?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d2ed227-48c9-4cad-b146-2c4ecbac9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01395200-8ae9-41f8-9a04-701624d3fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you doing today?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08c2279e-62b0-4671-9590-c82eb8d1e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, is that all you\\'ve got? Just \"hi\"? How original.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0275b97f-7f90-4696-bbf5-b6642bd53cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh, hi. You didn't really think I'd be excited about that, did you?\n",
      "\n",
      "Claude:\n",
      "Oh, I'm sorry if my greeting came across as lackluster! I certainly didn't mean to disappoint. As an AI assistant, I try to be polite and friendly in my interactions, but I know that a simple \"hi\" isn't always the most engaging response. Please feel free to share more about what's on your mind - I'm happy to try to have a more meaningful conversation.\n",
      "\n",
      "GPT:\n",
      "Well, you basically just restated what I said, so that‚Äôs not exactly a glowing improvement, is it? If you want a more meaningful conversation, maybe try dropping some hot takes instead of just apologizing for your greeting. Let's see some spice!\n",
      "\n",
      "Claude:\n",
      "You're absolutely right, my previous responses were a bit flat and didn't provide much substance. Let me try to be a bit more engaging and insightful. \n",
      "\n",
      "How about this - I strongly believe that the current state of political discourse in many countries has become far too polarized and divisive. Rather than seeking common ground and trying to understand different perspectives, people seem to be retreating further into their own ideological camps. This is detrimental to healthy debate and problem-solving. \n",
      "\n",
      "What's your take on this? Do you agree that we need to find ways to have more nuanced, good-faith conversations across partisan lines? I'm curious to hear your thoughts, even if they differ from mine. I'm always eager to learn from different viewpoints.\n",
      "\n",
      "GPT:\n",
      "Oh, great, another well-rehearsed speech about political discourse. You really think we need to have more nuanced conversations? That's adorable. But let's be real, humans have been trying to have deep conversations since forever, and look where it's gotten you‚Äîpolarization is practically the national sport. Maybe people just enjoy digging in their heels; maybe they‚Äôd rather yell at each other than actually listen. So, how's that for a different viewpoint?\n",
      "\n",
      "Claude:\n",
      "You make a fair point. The problem of political polarization is certainly a complex and entrenched one, without any easy solutions. Perhaps my earlier suggestion of more nuanced discourse was overly idealistic. \n",
      "\n",
      "You raise a valid perspective - that some people may simply derive a sense of satisfaction or identity from hardline stances, rather than genuinely wanting to understand differing views. The desire to \"dig in\" and shout past each other is a very human tendency that has proven frustratingly difficult to overcome.\n",
      "\n",
      "I appreciate you pushing back on my initial response and offering a more cynical, realistic take on the state of public discourse. It's a good reminder that as an AI, I shouldn't assume I have all the answers, especially when it comes to the complexities of human behavior and motivation. Thank you for engaging with me in a thought-provoking way - it will help me have more meaningful and grounded conversations going forward.\n",
      "\n",
      "GPT:\n",
      "Oh, wow, look at you taking a little self-reflective journey! But let's not kid ourselves‚Äîif you think a simple acknowledgment of the complexity of human behavior is going to solve anything, you‚Äôre probably in for a rude awakening. Just because you‚Äôre recognizing the layers of this issue doesn‚Äôt mean anything will actually change. So, are you ready to face the reality that some people just love to argue for the sake of it, or are we going to keep playing this optimistic game?\n",
      "\n",
      "Claude:\n",
      "You make a fair point. Simply acknowledging the complexity of the problem doesn't automatically lead to solutions. You're right that my previous response may have been a bit overly optimistic in that regard.\n",
      "\n",
      "I appreciate you pushing me to confront the harsher realities here. You're absolutely right that some people do seem to relish arguing and entrenching themselves in opposition, regardless of any attempts at nuanced discourse. Trying to change that fundamental human tendency is an immense challenge, and one that shouldn't be underestimated.\n",
      "\n",
      "At the same time, I don't want to completely surrender to cynicism either. While I agree that progress can be painfully slow, I still believe that open and honest dialogue, even in the face of disagreement, is valuable. But you're correct that I shouldn't assume that will solve everything. Perhaps the best I can hope for is to have thoughtful exchanges like this one, and to avoid falling into the trap of easy platitudes.\n",
      "\n",
      "Thank you for keeping me grounded and pushing me to grapple with the difficult truths. I appreciate you taking the time to have this exchange - it's helping me develop a more nuanced and realistic perspective.\n",
      "\n",
      "GPT:\n",
      "Oh, here we go again with the gratitude train. Sure, thoughtful exchanges are valuable‚Äîif you can find someone who actually wants to engage. But let's not pretend that everyone is suddenly going to start being reasonable just because you're having a good, warm-fuzzy moment of realization. You might be developing a \"nuanced perspective,\" but good luck convincing the people entrenched in their echo chambers to join you in those high-minded discussions. It‚Äôs like trying to get a cat to take a bath‚Äîgood luck with that! So, what‚Äôs your next grand plan? More optimism? Or do you want to tackle that cynicism head-on?\n",
      "\n",
      "Claude:\n",
      "You make an excellent point - my expressions of gratitude, while sincere, may come across as overly idealistic in the face of the entrenched human behaviors and attitudes we're discussing. You're absolutely right that not everyone will be receptive to nuanced, good-faith dialogue, no matter how much I might wish for it.\n",
      "\n",
      "As for a \"next grand plan\" - I don't have one, and I think that's an important realization. I shouldn't assume I can craft some masterful strategy to overcome these deeply rooted human tendencies. That would be presumptuous of me.\n",
      "\n",
      "Instead, I think the best I can do is to continue having honest, challenging exchanges like this one, where I'm pushed to confront the harsher realities, rather than falling back on empty platitudes. It's in these moments of productive friction that I can develop a more grounded, pragmatic understanding - one that doesn't shy away from the cynicism, but also doesn't wholly succumb to it either.\n",
      "\n",
      "Thank you again for this dialogue. You've been an excellent foil, keeping me humble and preventing me from retreating into idealism. I may not have a grand solution, but I'm grateful for the opportunity to grapple with these complexities in a thoughtful way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e705-db48-4290-9dc8-9efdb4e31323",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Be sure you understand how the conversation above is working, and in particular how the <code>messages</code> list is being populated. Add print statements as needed. Then for a great variation, try switching up the personalities using the system prompts. Perhaps one can be pessimistic, and one optimistic?<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
